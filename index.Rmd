---
title: "Decoding KPOP vs. KRnB"
output:
    flexdashboard::flex_dashboard:
      storyboard: true
      theme: flatly
author: Ananta Wibisono
      
date: "2024-02-14"
---

```{r asdfsadf, echo=FALSE}
library(spotifyr)
krnb <- get_playlist_audio_features("", "5k7upSNskiHxxf6DSFnHD1")
kpop <- get_playlist_audio_features("", "25tn6jO4XMfbtSv9ukYvYt")
krnb_general <- get_playlist_audio_features("", "2TJHOlrTUoLMHs9CTyxN9n")
krnb_general_50 <- head(krnb_general, 50)
kpop_general <- get_playlist_audio_features("", "37i9dQZF1DX9tPFwDMOaN1")

kpop_general_sorted <- kpop_general[order(kpop_general$energy), ]

# Remove the 5 lowest energy tracks
kpop_general_49 <- kpop_general_sorted[-(1:5), ]



warr <- get_track_audio_features(c("1ZEFYW6nPEvIcsIvymgsLk", "3DBKc4ioGnMQLlbGQcFDIO"))

library(ggplot2)
library(plotly)
library(dplyr)
library(tibble)
library(compmus)
library(tidyr)
library(purrr)

# Add a column to each dataframe to specify the genre for labeling on the plot
krnb$genre <- "krnb"
kpop$genre <- "kpop"
krnb_general_50$genre <- "krnb"
kpop_general$genre <- "kpop"

# Combine the dataframes
combined_data <- rbind(krnb, kpop, krnb_general_50, kpop_general)

circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

#combined_data
#colnames(combined_data)
```

Key Analysis
========================================

Column {.tabset}
-------------------------------------
### Key Histogram

```{r key_histogram plot, echo=FALSE}
# Dkey <- combined_data %>%
#   arrange(desc(track.popularity)) %>%
#   filter(key_name == 'D')
# 
# # View the filtered data
# print(Dkey[, c("track.name", "key_name", "track.popularity", "track.album.name")])
# 
# Gkey <- combined_data %>%
#   arrange(desc(track.popularity)) %>%
#   filter(key_name == 'G')
# 
# # View the filtered data
# print(Gkey[, c("track.name", "key_name", "track.popularity", "track.album.name")])


ggplot(combined_data, aes(x = key_name, fill = genre)) + 
  geom_bar() +
  facet_wrap(~genre, scales = "free") +
  labs(title = "Histogram of Keys by Genre", x = "key")

```

### D key song
```{r chordogram1 plot, echo=FALSE}
twenty_five <-
  get_tidy_audio_analysis("3m5PgWSClkZ44vdFmPiqpq") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

twenty_five |> 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(title = "Keygram: Yes or No", x = "Time (s)", y = "")
```

### G key song
```{r chordogram2 plot, echo=FALSE}
twenty_five <-
  get_tidy_audio_analysis("4RiudH8RehvLLrk8uNgIdR") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

twenty_five |> 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() + 
  geom_vline(xintercept = 89.55, color = "red", size = 0.65) +
  geom_vline(xintercept = 153, color = "red", size = 0.65) +
  labs(title = "Keygram: Nightwalker", x = "Time (s)", y = "")
```


Column {data-width=275}
-------------------------------------

**Key Histogram**

In the genre of KPOP, the most prevalent keys are C sharp, F, and G, as indicated by the plots. Conversely, in KRnB, the histogram reveals that the A and G key is favored among other keys.

In KPOP, the prevalence of C sharp, F, and G keys mirrors their common usage in Western pop music, suggesting a shared musical influence between the two genres. Conversely, within KRnB, the dominance of the A and G keys underscores the unique tonal preferences characteristic of Korean R&B music. These trends underscore the dynamic interplay between cultural influences and genre-specific characteristics, illustrating how musical styles can both converge and diverge across different contexts.

**Keygrams for songs in different keys**

In looking at the keygrams of the most popular songs in your collection, some interesting patterns emerge regarding their tonal centers.

For instance, when looking at the song in the key of D, we notice that the confidence for D minor key dominates, which suggests a strong association with that tonality. But what's really interesting is that the confidence for C sharp minor key pops up even more frequently than for D minor. This might be because of some connection between D minor and C sharp minor keys. The keys share some of the same notes, which could explain why C sharp minor shows up so prominently alongside D minor.

Now, the keygram of the song in G key is a bit more straightforward. It's clear that both G minor and major keys rule the roost throughout the song, indicating a strong focus on G as the tonal center. Also interesting to note: there are a couple of moments in the song where the keygram isn't too sure about which key it's in, besides the usual uncertainty at the beginning and end of songs. These moments of uncertainty could signal shifts in harmony or brief changes in tonality within the song.


Self similarity matrices
========================================

Column {data-width=750}
-------------------------------------

### Self similarity matrix

```{r self plot, echo=FALSE}
bzt <-
  get_tidy_audio_analysis("1ZEFYW6nPEvIcsIvymgsLk") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )
```

```{r self plot2, echo=FALSE}
  bzt |>
  compmus_self_similarity(timbre, "cosine") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "") + labs(title = "WA-R-R - Colde")
```

Column {data-width=250}
-------------------------------------
**Description**

no description yet 

this is my fav song tho btw

Chroma and Timbre plots
========================================

Column {.tabset}
-------------------------------------

### Lowest Energy Song Chromagram

```{r chromagram, echo=FALSE}


wood1 <-
  get_tidy_audio_analysis("2bdVgAQgosGUJoViVDNeOV") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

wood1 |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c() +
  labs(title = "LIMBO - Keshi")
```

### Highest Energy Song Chromagram

```{r chromagram2, echo=FALSE}
library(tidyr)
library(purrr)

wood2 <-
  get_tidy_audio_analysis("0RDqNCRBGrSegk16Avfzuq") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

wood2 |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c() + labs(title = "Talk that Talk - TWICE")
```



Column {data-width=150}
-------------------------------------

**Description**

no description yet

Overview
========================================

Column {data-width=500}
-------------------------------------

### Corpus Description

**Introduction**

I've put together a collection of playlists that represent my taste in music, particularly focusing on KRnB and KPOP genres. These playlists consist of four categories: two are tailored to my personal preferences in KRnB and KPOP, while the other two feature more general KRnB and KPOP tracks. The selection of these playlists is based on my deep love for KRnB and KPOP music.

The personal playlists are curated by Spotify, using my listening history to tailor the content to my tastes. On the other hand, the broader KRnB and KPOP playlists are popular among a wider audience.

With this collection, I aim to analyze and understand the differences between KRnB and KPOP. I'm also interested in exploring why I prefer certain KPOP and KRnB tracks over others. This analysis will help me gain insights into my music preferences and the unique characteristics of these genres.



Column {data-width=500}
-------------------------------------

![]("C:\Users\anant\Downloads\overview.png")


Corpus Analysis
========================================



Column {.tabset}
-------------------------------------

### Energy Distribution

```{r difference in tempo, echo=FALSE}
# Calculate mean values
krnb_mean <- mean(krnb$energy)
kpop_mean <- mean(kpop$energy)
gen_krnb_mean <- mean(krnb_general_50$energy)
gen_kpop_mean <- mean(kpop_general_49$energy)

# Plot with mean lines
histies <- ggplot() +
  geom_histogram(data = krnb, aes(x = energy, fill = "Personal Korean R&B Mix"), alpha = 0.5) +
  geom_histogram(data = kpop, aes(x = energy, fill = "Personal K-POP Mix"), alpha = 0.5) +
  geom_histogram(data = krnb_general_50, aes(x = energy, fill = "General Korean R&B"), alpha = 0.5) +
  geom_histogram(data = kpop_general_49, aes(x = energy, fill = "General K-POP"), alpha = 0.5) +
  geom_vline(xintercept = krnb_mean, color = "green", linetype = "twodash", size = 0.5) + 
  geom_vline(xintercept = kpop_mean, color = "red", linetype = "twodash", size = 0.5) +    
  geom_vline(xintercept = gen_krnb_mean, color = "blue", linetype = "twodash", size = 0.5) + 
  geom_vline(xintercept = gen_kpop_mean, color = "yellow", linetype = "twodash", size = 0.5) +  
  scale_fill_manual(name = "Genre", values = c("Personal Korean R&B Mix" = "green", "Personal K-POP Mix" = "red", "General Korean R&B" = "blue", "General K-POP" = "yellow" )) +
  theme(legend.position = "right") + labs(title = "Energy Difference between Krnb and Kpop") + theme_classic() 

histies <- ggplotly(histies)

histies
```

### Acousticness Comparison

```{r timbre plot, echo=FALSE}
library(Hmisc)

# Create a boxplot for acousticness
boxplot_acousticness <- ggplot(combined_data, aes(x = genre, y = acousticness, fill = genre)) +
  geom_boxplot() +
  labs(title = "Comparison of Acousticness between krnb and kpop", x = "Genre", y = "Acousticness") +
  scale_fill_manual(values = c("krnb" = "purple", "kpop" = "green")) +
  theme_minimal()


boxplot_acousticness <- ggplotly(boxplot_acousticness)

boxplot_acousticness


```

```{r f, echo=FALSE}
# Find the row with the maximum acousticness value
max_acousticness_row <- combined_data[which.min(combined_data$acousticness), ]

# Print the row
print(max_acousticness_row)
```

Column {data-width=250}
-------------------------------------

**Energy Distribution**

In this plot I pulled in data of 4 different playlists: 

1. My Personal KrnB playlist
2. My Personal Kpop playlist
3. A popular KRnB playlist
4. A popular KPOP playlist

Let's first look at the personal playlists by selecting that option in the plot legend.

What we see is that, on average, KPOP songs tend to have higher energy levels compared to KRnB. But there's a catch – there's some overlap between the two genres. This means that a KRnB track could have the energy level typical of a KPOP song, and vice versa. It goes to show that energy level is just one factor among many that define a song's genre.

Now, when we switch over to the general playlists, things look different. The songs seem more spread out across energy levels compared to the personal playlists. This suggests that personally, I might have a specific energy level in mind when picking KRnB or KPOP songs for my playlists. It's all about personal taste and what vibes with me the most.

**Acousticness Comparison**


Looking at the plot, it's clear that KRnB songs tend to have higher acousticness compared to KPOP tunes. There's just a small sliver of overlap between the acousticness of KRnB and KPOP tracks. Also, notice how the range of acousticness for KRnB songs is wider than that of KPOP. This suggests that KRnB artists have more leeway in using different instruments compared to the more structured sound of KPOP.



Relation between loudness and energy
========================================


Column {.tabset}
-------------------------------------

### Relation Plot

```{r energy plot, echo=FALSE}
corr_plot <- ggplot() +
  geom_point(data = krnb, aes(energy, loudness, color = "krnb", size = valence, text = track.name), alpha = 0.7) +
  geom_point(data = kpop, aes(energy, loudness, color = "kpop", size = valence, text = track.name), alpha = 0.7) +
  # Calculate and add a linear regression line through all points
  geom_smooth(data = rbind(krnb, kpop), aes(energy, loudness), method = "lm", se = FALSE, color = "red", alpha = 0.4) +
  scale_color_manual(values = c("krnb" = "blue", "kpop" = "green"),
                     labels = c("kpop", "krnb"),
                     name = "Genres") + 
  labs(title = "Energy vs Loudness with Valence as size")

corr_plot <- ggplotly(corr_plot, tooltip = c("text"))

corr_plot
```




Column {data-width=250}
-------------------------------------



**Description**

In the plot, you can clearly see how energy and loudness are linked, especially with that regression line slicing through the data points. There's also this faint boundary line that seems to separate KPOP and KRnB songs. Oh, and there's this one standout: the KPOP hit "Cupid" by Fifty Fifty, chilling in the KRnB zone for loudness and energy. Just hover over the point to check it out!


